[2016-04-02 22:10:55,442] TRACE Controller 0 epoch 4 started leader election for partition [test,0] (state.change.logger)
[2016-04-02 22:10:55,481] ERROR Controller 0 epoch 4 initiated state change for partition [test,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [test,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:357)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:206)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:743)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:95)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:95)
	at scala.collection.Iterator$class.foreach(Iterator.scala:772)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:45)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:95)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:742)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:314)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:161)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:81)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1109)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1107)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1107)
	at kafka.utils.Utils$.inLock(Utils.scala:535)
	at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1107)
	at org.I0Itec.zkclient.ZkClient$4.run(ZkClient.java:472)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
[2016-04-02 22:10:55,543] TRACE Controller 0 epoch 4 started leader election for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:10:55,559] ERROR Controller 0 epoch 4 initiated state change for partition [iotdogs,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [iotdogs,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:357)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:206)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:743)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:95)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:95)
	at scala.collection.Iterator$class.foreach(Iterator.scala:772)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:45)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:95)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:742)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:314)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:161)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:81)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1109)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1107)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1107)
	at kafka.utils.Utils$.inLock(Utils.scala:535)
	at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1107)
	at org.I0Itec.zkclient.ZkClient$4.run(ZkClient.java:472)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
[2016-04-02 22:11:05,915] TRACE Controller 0 epoch 4 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:2,ControllerEpoch:3) with correlationId 9 to broker 0 for partition [test,0] (state.change.logger)
[2016-04-02 22:11:05,915] TRACE Controller 0 epoch 4 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:2,ControllerEpoch:3) with correlationId 9 to broker 0 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:11:05,915] TRACE Controller 0 epoch 4 changed state of replica 0 for partition [test,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-04-02 22:11:05,915] TRACE Controller 0 epoch 4 changed state of replica 0 for partition [iotdogs,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-04-02 22:11:05,915] TRACE Controller 0 epoch 4 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:2,ControllerEpoch:3) with correlationId 10 to broker 0 for partition [test,0] (state.change.logger)
[2016-04-02 22:11:05,915] TRACE Controller 0 epoch 4 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:2,ControllerEpoch:3) with correlationId 10 to broker 0 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:11:05,915] TRACE Controller 0 epoch 4 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:2,ControllerEpoch:3) with correlationId 10 to broker 0 for partition [test,0] (state.change.logger)
[2016-04-02 22:11:05,915] TRACE Controller 0 epoch 4 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:2,ControllerEpoch:3) with correlationId 10 to broker 0 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:11:05,915] TRACE Controller 0 epoch 4 started leader election for partition [test,0] (state.change.logger)
[2016-04-02 22:11:05,977] TRACE Controller 0 epoch 4 elected leader 0 for Offline partition [test,0] (state.change.logger)
[2016-04-02 22:11:05,977] TRACE Controller 0 epoch 4 changed partition [test,0] from OfflinePartition to OnlinePartition with leader 0 (state.change.logger)
[2016-04-02 22:11:05,977] TRACE Controller 0 epoch 4 started leader election for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:11:06,040] TRACE Controller 0 epoch 4 elected leader 0 for Offline partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:11:06,040] TRACE Controller 0 epoch 4 changed partition [iotdogs,0] from OfflinePartition to OnlinePartition with leader 0 (state.change.logger)
[2016-04-02 22:11:06,040] TRACE Controller 0 epoch 4 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4) with correlationId 11 to broker 0 for partition [test,0] (state.change.logger)
[2016-04-02 22:11:06,040] TRACE Controller 0 epoch 4 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4) with correlationId 11 to broker 0 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:11:06,040] TRACE Controller 0 epoch 4 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4) with correlationId 11 to broker 0 for partition [test,0] (state.change.logger)
[2016-04-02 22:11:06,040] TRACE Controller 0 epoch 4 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4) with correlationId 11 to broker 0 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:12:06,557] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:2,ControllerEpoch:3),ReplicationFactor:1),AllReplicas:0) for partition [test,0] in response to UpdateMetadata request sent by controller 0 epoch 4 with correlation id 9 (state.change.logger)
[2016-04-02 22:12:06,557] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:2,ControllerEpoch:3),ReplicationFactor:1),AllReplicas:0) for partition [iotdogs,0] in response to UpdateMetadata request sent by controller 0 epoch 4 with correlation id 9 (state.change.logger)
[2016-04-02 22:12:06,557] TRACE Controller 0 epoch 4 received response UpdateMetadataResponse(9,0) for a request sent to broker id:0,host:Oscar,port:9092 (state.change.logger)
[2016-04-02 22:12:06,557] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:2,ControllerEpoch:3),ReplicationFactor:1),AllReplicas:0) correlation id 10 from controller 0 epoch 4 for partition [test,0] (state.change.logger)
[2016-04-02 22:12:06,557] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:2,ControllerEpoch:3),ReplicationFactor:1),AllReplicas:0) correlation id 10 from controller 0 epoch 4 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:12:06,557] WARN Broker 0 ignoring LeaderAndIsr request from controller 0 with correlation id 10 epoch 4 for partition [test,0] since its associated leader epoch 2 is old. Current leader epoch is 2 (state.change.logger)
[2016-04-02 22:12:06,557] WARN Broker 0 ignoring LeaderAndIsr request from controller 0 with correlation id 10 epoch 4 for partition [iotdogs,0] since its associated leader epoch 2 is old. Current leader epoch is 2 (state.change.logger)
[2016-04-02 22:12:06,557] TRACE Controller 0 epoch 4 received response LeaderAndIsrResponse(10,Map((test,0) -> 13, (iotdogs,0) -> 13),0) for a request sent to broker id:0,host:Oscar,port:9092 (state.change.logger)
[2016-04-02 22:12:06,557] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:2,ControllerEpoch:3),ReplicationFactor:1),AllReplicas:0) for partition [test,0] in response to UpdateMetadata request sent by controller 0 epoch 4 with correlation id 10 (state.change.logger)
[2016-04-02 22:12:06,557] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:2,ControllerEpoch:3),ReplicationFactor:1),AllReplicas:0) for partition [iotdogs,0] in response to UpdateMetadata request sent by controller 0 epoch 4 with correlation id 10 (state.change.logger)
[2016-04-02 22:12:06,557] TRACE Controller 0 epoch 4 received response UpdateMetadataResponse(10,0) for a request sent to broker id:0,host:Oscar,port:9092 (state.change.logger)
[2016-04-02 22:12:06,557] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4),ReplicationFactor:1),AllReplicas:0) correlation id 11 from controller 0 epoch 4 for partition [test,0] (state.change.logger)
[2016-04-02 22:12:06,557] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4),ReplicationFactor:1),AllReplicas:0) correlation id 11 from controller 0 epoch 4 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:12:06,557] TRACE Broker 0 handling LeaderAndIsr request correlationId 11 from controller 0 epoch 4 starting the become-leader transition for partition [test,0] (state.change.logger)
[2016-04-02 22:12:06,557] TRACE Broker 0 handling LeaderAndIsr request correlationId 11 from controller 0 epoch 4 starting the become-leader transition for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:12:06,557] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 0 epoch 4 with correlation id 11 for partition [test,0] (state.change.logger)
[2016-04-02 22:12:06,557] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 0 epoch 4 with correlation id 11 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:12:06,573] TRACE Broker 0 completed LeaderAndIsr request correlationId 11 from controller 0 epoch 4 for the become-leader transition for partition [test,0] (state.change.logger)
[2016-04-02 22:12:06,573] TRACE Broker 0 completed LeaderAndIsr request correlationId 11 from controller 0 epoch 4 for the become-leader transition for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:12:06,573] TRACE Controller 0 epoch 4 received response LeaderAndIsrResponse(11,Map((test,0) -> 0, (iotdogs,0) -> 0),0) for a request sent to broker id:0,host:Oscar,port:9092 (state.change.logger)
[2016-04-02 22:12:06,573] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4),ReplicationFactor:1),AllReplicas:0) for partition [test,0] in response to UpdateMetadata request sent by controller 0 epoch 4 with correlation id 11 (state.change.logger)
[2016-04-02 22:12:06,573] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4),ReplicationFactor:1),AllReplicas:0) for partition [iotdogs,0] in response to UpdateMetadata request sent by controller 0 epoch 4 with correlation id 11 (state.change.logger)
[2016-04-02 22:12:06,573] TRACE Controller 0 epoch 4 received response UpdateMetadataResponse(11,0) for a request sent to broker id:0,host:Oscar,port:9092 (state.change.logger)
[2016-04-02 22:41:38,116] TRACE Controller 0 epoch 5 started leader election for partition [test,0] (state.change.logger)
[2016-04-02 22:41:38,147] ERROR Controller 0 epoch 5 initiated state change for partition [test,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [test,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:357)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:206)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:743)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:95)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:95)
	at scala.collection.Iterator$class.foreach(Iterator.scala:772)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:45)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:95)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:742)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:314)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:161)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:81)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:49)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:47)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:47)
	at kafka.utils.Utils$.inLock(Utils.scala:535)
	at kafka.server.ZookeeperLeaderElector.startup(ZookeeperLeaderElector.scala:47)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply$mcV$sp(KafkaController.scala:650)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:646)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:646)
	at kafka.utils.Utils$.inLock(Utils.scala:535)
	at kafka.controller.KafkaController.startup(KafkaController.scala:646)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:117)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:29)
	at kafka.Kafka$.main(Kafka.scala:46)
	at kafka.Kafka.main(Kafka.scala)
[2016-04-02 22:41:38,147] TRACE Controller 0 epoch 5 started leader election for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:41:38,179] ERROR Controller 0 epoch 5 initiated state change for partition [iotdogs,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [iotdogs,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:357)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:206)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:743)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:95)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:95)
	at scala.collection.Iterator$class.foreach(Iterator.scala:772)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:45)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:95)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:742)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:314)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:161)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:81)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:49)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:47)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:47)
	at kafka.utils.Utils$.inLock(Utils.scala:535)
	at kafka.server.ZookeeperLeaderElector.startup(ZookeeperLeaderElector.scala:47)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply$mcV$sp(KafkaController.scala:650)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:646)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:646)
	at kafka.utils.Utils$.inLock(Utils.scala:535)
	at kafka.controller.KafkaController.startup(KafkaController.scala:646)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:117)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:29)
	at kafka.Kafka$.main(Kafka.scala:46)
	at kafka.Kafka.main(Kafka.scala)
[2016-04-02 22:41:47,703] TRACE Controller 0 epoch 5 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4) with correlationId 3 to broker 0 for partition [test,0] (state.change.logger)
[2016-04-02 22:41:47,703] TRACE Controller 0 epoch 5 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4) with correlationId 3 to broker 0 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:41:47,719] TRACE Controller 0 epoch 5 changed state of replica 0 for partition [test,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-04-02 22:41:47,734] TRACE Controller 0 epoch 5 changed state of replica 0 for partition [iotdogs,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-04-02 22:41:47,734] TRACE Controller 0 epoch 5 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4) with correlationId 4 to broker 0 for partition [test,0] (state.change.logger)
[2016-04-02 22:41:47,734] TRACE Controller 0 epoch 5 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4) with correlationId 4 to broker 0 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:41:47,734] TRACE Controller 0 epoch 5 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4) with correlationId 4 to broker 0 for partition [test,0] (state.change.logger)
[2016-04-02 22:41:47,734] TRACE Controller 0 epoch 5 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4) with correlationId 4 to broker 0 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:41:47,734] TRACE Controller 0 epoch 5 started leader election for partition [test,0] (state.change.logger)
[2016-04-02 22:41:47,766] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4),ReplicationFactor:1),AllReplicas:0) for partition [test,0] in response to UpdateMetadata request sent by controller 0 epoch 5 with correlation id 3 (state.change.logger)
[2016-04-02 22:41:47,766] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4),ReplicationFactor:1),AllReplicas:0) for partition [iotdogs,0] in response to UpdateMetadata request sent by controller 0 epoch 5 with correlation id 3 (state.change.logger)
[2016-04-02 22:41:47,781] TRACE Controller 0 epoch 5 received response UpdateMetadataResponse(3,0) for a request sent to broker id:0,host:Oscar,port:9092 (state.change.logger)
[2016-04-02 22:41:47,797] TRACE Controller 0 epoch 5 elected leader 0 for Offline partition [test,0] (state.change.logger)
[2016-04-02 22:41:47,797] TRACE Controller 0 epoch 5 changed partition [test,0] from OfflinePartition to OnlinePartition with leader 0 (state.change.logger)
[2016-04-02 22:41:47,797] TRACE Controller 0 epoch 5 started leader election for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:41:47,859] TRACE Controller 0 epoch 5 elected leader 0 for Offline partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:41:47,859] TRACE Controller 0 epoch 5 changed partition [iotdogs,0] from OfflinePartition to OnlinePartition with leader 0 (state.change.logger)
[2016-04-02 22:41:47,859] TRACE Controller 0 epoch 5 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:5) with correlationId 5 to broker 0 for partition [test,0] (state.change.logger)
[2016-04-02 22:41:47,859] TRACE Controller 0 epoch 5 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:5) with correlationId 5 to broker 0 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:41:47,859] TRACE Controller 0 epoch 5 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:5) with correlationId 5 to broker 0 for partition [test,0] (state.change.logger)
[2016-04-02 22:41:47,859] TRACE Controller 0 epoch 5 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:5) with correlationId 5 to broker 0 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:41:47,859] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4),ReplicationFactor:1),AllReplicas:0) correlation id 4 from controller 0 epoch 5 for partition [test,0] (state.change.logger)
[2016-04-02 22:41:47,859] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4),ReplicationFactor:1),AllReplicas:0) correlation id 4 from controller 0 epoch 5 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:41:47,875] TRACE Broker 0 handling LeaderAndIsr request correlationId 4 from controller 0 epoch 5 starting the become-leader transition for partition [test,0] (state.change.logger)
[2016-04-02 22:41:47,875] TRACE Broker 0 handling LeaderAndIsr request correlationId 4 from controller 0 epoch 5 starting the become-leader transition for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:41:47,891] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 0 epoch 5 with correlation id 4 for partition [test,0] (state.change.logger)
[2016-04-02 22:41:47,891] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 0 epoch 5 with correlation id 4 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:41:47,937] TRACE Broker 0 completed LeaderAndIsr request correlationId 4 from controller 0 epoch 5 for the become-leader transition for partition [test,0] (state.change.logger)
[2016-04-02 22:41:47,937] TRACE Broker 0 completed LeaderAndIsr request correlationId 4 from controller 0 epoch 5 for the become-leader transition for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:41:47,937] TRACE Controller 0 epoch 5 received response LeaderAndIsrResponse(4,Map((test,0) -> 0, (iotdogs,0) -> 0),0) for a request sent to broker id:0,host:Oscar,port:9092 (state.change.logger)
[2016-04-02 22:41:47,937] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4),ReplicationFactor:1),AllReplicas:0) for partition [test,0] in response to UpdateMetadata request sent by controller 0 epoch 5 with correlation id 4 (state.change.logger)
[2016-04-02 22:41:47,937] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:4),ReplicationFactor:1),AllReplicas:0) for partition [iotdogs,0] in response to UpdateMetadata request sent by controller 0 epoch 5 with correlation id 4 (state.change.logger)
[2016-04-02 22:41:47,937] TRACE Controller 0 epoch 5 received response UpdateMetadataResponse(4,0) for a request sent to broker id:0,host:Oscar,port:9092 (state.change.logger)
[2016-04-02 22:41:47,937] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:5),ReplicationFactor:1),AllReplicas:0) correlation id 5 from controller 0 epoch 5 for partition [test,0] (state.change.logger)
[2016-04-02 22:41:47,937] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:5),ReplicationFactor:1),AllReplicas:0) correlation id 5 from controller 0 epoch 5 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:41:47,937] TRACE Broker 0 handling LeaderAndIsr request correlationId 5 from controller 0 epoch 5 starting the become-leader transition for partition [test,0] (state.change.logger)
[2016-04-02 22:41:47,953] TRACE Broker 0 handling LeaderAndIsr request correlationId 5 from controller 0 epoch 5 starting the become-leader transition for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:41:47,953] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 0 epoch 5 with correlation id 5 for partition [test,0] (state.change.logger)
[2016-04-02 22:41:47,953] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 0 epoch 5 with correlation id 5 for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:41:47,953] TRACE Broker 0 completed LeaderAndIsr request correlationId 5 from controller 0 epoch 5 for the become-leader transition for partition [test,0] (state.change.logger)
[2016-04-02 22:41:47,953] TRACE Broker 0 completed LeaderAndIsr request correlationId 5 from controller 0 epoch 5 for the become-leader transition for partition [iotdogs,0] (state.change.logger)
[2016-04-02 22:41:47,953] TRACE Controller 0 epoch 5 received response LeaderAndIsrResponse(5,Map((test,0) -> 0, (iotdogs,0) -> 0),0) for a request sent to broker id:0,host:Oscar,port:9092 (state.change.logger)
[2016-04-02 22:41:47,953] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:5),ReplicationFactor:1),AllReplicas:0) for partition [test,0] in response to UpdateMetadata request sent by controller 0 epoch 5 with correlation id 5 (state.change.logger)
[2016-04-02 22:41:47,953] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:5),ReplicationFactor:1),AllReplicas:0) for partition [iotdogs,0] in response to UpdateMetadata request sent by controller 0 epoch 5 with correlation id 5 (state.change.logger)
[2016-04-02 22:41:47,953] TRACE Controller 0 epoch 5 received response UpdateMetadataResponse(5,0) for a request sent to broker id:0,host:Oscar,port:9092 (state.change.logger)
